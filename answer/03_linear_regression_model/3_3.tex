\RequirePackage[l2tabu, orthodox]{nag}

\documentclass{jsarticle}
\usepackage[dvipdfmx]{graphicx}
\usepackage{physics}
\usepackage{amsmath,amssymb}

\title{PRML解答集}

\date{\today}
\begin{document}
\maketitle

問題3.3 \\
それぞれのデータ点$t_n$に重み要素$r_n > 0$が割り当てられており，二乗和誤差関数が
\begin{equation}
    E_D(w) = \cfrac{1}{2} \sum_{n=1}^{N}r_n \{t_n - \boldsymbol{w}^T \phi (\boldsymbol{x}_n) \tag{3.104} \}^2
\end{equation}
となるデータ集合を考える．このとき，この誤差関数を最小にする解$\boldsymbol{w}^{*}$についての式を求めよ．
また，(i)ノイズの分散がデータに依存する場合，(ii)データ点に重複がある場合に照らして，それぞれ重み付き二乗和誤差関数の解釈を与えよ。

方針3.3 \\

解答3.3 \\

$\boldsymbol{\phi} = (\phi(\boldsymbol{x_1}), \phi(\boldsymbol{x_2}), \ldots, \phi(\boldsymbol{x_n}))^T$, $\boldsymbol{D} = diag(r_1,\ldots,r_n)$とすると

$$ E_D(w) = \cfrac{1}{2} (\boldsymbol{t} - \boldsymbol{\phi}\boldsymbol{w})^T\boldsymbol{D}(\boldsymbol{t} - \boldsymbol{\phi}\boldsymbol{w}) $$

と表せる．上式を$\boldsymbol{w}$で微分すると

\begin{eqnarray*}
    \cfrac{\partial}{\partial \boldsymbol{w}} E_D(\boldsymbol{w})
    &=& \cfrac{\partial}{\partial \boldsymbol{w}} \left\{ \cfrac{1}{2} (\boldsymbol{t}^T - \boldsymbol{w}^T \boldsymbol{\phi}^T)\boldsymbol{D}
    (\boldsymbol{t} - \boldsymbol{\phi}\boldsymbol{w} )  \right\} \\
    &=& \cfrac{\partial}{\partial \boldsymbol{w}} \left\{ \cfrac{1}{2} ( \boldsymbol{t}^T \boldsymbol{D}\boldsymbol{t}
    - \boldsymbol{t}^T \boldsymbol{D} \boldsymbol{\phi} \boldsymbol{w}
    - \boldsymbol{w}^T \boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{t}
    + \boldsymbol{w}^T \boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{\phi} \boldsymbol{w}) \right\} \\
    &=& \boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{\phi} \boldsymbol{w} - \boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{t}
\end{eqnarray*}

なお，ここでは以下の微分公式を利用．

\begin{equation}
    \cfrac{\partial}{\partial \boldsymbol{x}} (\boldsymbol{x}^T \boldsymbol{a})
    = \cfrac{\partial}{\partial \boldsymbol{x}} (\boldsymbol{a}^T \boldsymbol{x})
    = \boldsymbol{a} \tag{C.19}
\end{equation}

\begin{eqnarray*}
    \cfrac{\partial}{\partial \boldsymbol{x}}(\boldsymbol{x}^T \boldsymbol{A} \boldsymbol{x})
    = 2\boldsymbol{A}\boldsymbol{x} (Aは対角行列)
\end{eqnarray*}

$\cfrac{\partial}{\partial \boldsymbol{w}} E_D(\boldsymbol{w}) = 0$を満たす$\boldsymbol{w}$が誤差関数を最小にする
$\boldsymbol{w}^{*}$であり，計算すると

$$ \boldsymbol{w}^{*} = (\boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{\phi})^{-1} \boldsymbol{\phi}^T \boldsymbol{D} \boldsymbol{t} $$

となる．\\

誤差関数の解釈

(i) ノイズの分散がデータに依存する場合 

(3.10)にて、右辺の$\beta$が$n$に依存しているということなので、

\begin{eqnarray*}
    P(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \boldsymbol{\beta})
    = \prod_{n=1}^N N(t_n | \boldsymbol{w}^T \boldsymbol{\phi(\boldsymbol{x_n}}), \beta_n^{-1})
\end{eqnarray*}

\begin{eqnarray*}
    \log P(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{w}, \boldsymbol{\beta})
    &=& \sum_{n=1}^N \log \exp \left\{ - \cfrac{1}{2} \beta_n (t_n - \boldsymbol{w}^T \boldsymbol{\phi(\boldsymbol{x_n})})^2 \right\} + (wに依らない項) \\
    &=& \cfrac{1}{2} \sum_{n=1}^N \beta_n (t_n - \boldsymbol{w}^T \boldsymbol{\phi(\boldsymbol{x_n})})^2 + const
\end{eqnarray*}

となり，(3.104)の誤差関数が出現する．

(ii)データ点の重複がある場合

(3.104)の式の形から，ある$n$についてのデータ$(t_n, \boldsymbol{x_n}$)が$r_n$個ずつある時の二乗和誤差
を表していることが分かる．

\newpage

問題3.6 \\

ガウス分布に従う複数の目標変数$\boldsymbol{t}$を持つ次の形の線形基底関数モデルを考える．

\begin{equation}
    p(\boldsymbol{t}|\boldsymbol{W}, \boldsymbol{\Sigma})
    = N(\boldsymbol{t}|\boldsymbol{x}, \boldsymbol{W}, \boldsymbol{\Sigma}) \tag{3.107}
\end{equation}

ただし，

\begin{equation}
    y(\boldsymbol{x}, \boldsymbol{W}) = \boldsymbol{W}^T \phi (\boldsymbol{x}) \tag{3.108}
\end{equation}

である．入力基底ベクトル$\phi(\boldsymbol{x}_n) (n=1,\ldots,N)$とそれに対応する目標ベクトル$\boldsymbol{t}_n$が
訓練データ集合として与えられるとき，パラメータ行列$\boldsymbol{W}$の最尤推定解$\boldsymbol{W}_{ML}$のそれぞれの
列が，等方性のノイズ分布に対する解の(3.15)の形の式で与えられることを示せ．これは共分散行列$\boldsymbol{\Sigma}$には
よらないことに注意せよ．さらに，$\boldsymbol{\Sigma}$の最尤指定解が

\begin{equation}
    \boldsymbol{\Sigma} = \cfrac{1}{N} \sum_{n=1}^N (t_n - \boldsymbol{W}_{ML} \phi(\boldsymbol{x}_n))
    (t_n - \boldsymbol{W}_{ML} \phi(\boldsymbol{x}_n))^T \tag{3.109}
\end{equation}

で与えられることを示せ．

方針3.6 \\

解答3.6 \\
\noindent
$X$: 入力ベクトル$x_1, \ldots x_n$を並べた行列 \\
とする.
対数尤度関数は

\begin{align*}
    \ln P(T|X,W,\Sigma)
    = \sum_{n=1}^N \ln N(t_n|W^T\phi(x_n), \Sigma) \\
    = -\cfrac{NK}{2}\ln (2\pi) - \cfrac{N}{2} \ln |\Sigma| - \cfrac{1}{2}\sum_{n=1}^N(t_n - w^T\phi)^T \Sigma^{-1} (t_n-w^T\phi_n)
\end{align*}

となる.

\begin{align*}
    \cfrac{\partial}{\partial X} (Xb + c)^T D (Xb + c) = (D + D^T)(Xb+c)b^T
\end{align*}

ここで,$T$を$n$番目の行が$t_n^T$となる$N \times K$行列とし, 上記の公式を用いて$W^T$に関する微分計算をすると

\begin{align*}
    \cfrac{\partial}{\partial W^T} \ln P(T|X, W, \Sigma)
    = \sum_{n=1}^N \Sigma^{-1}(t_n - w^T\phi_n)\phi_n^T
\end{align*}

これを$\textbf{0}$とおくと, 
\begin{align*}
    \sum_{n=1}^N \Sigma^{-1}(t_n - w^T\phi_n)\phi_n^T
    = \textbf{0} \\
    \Leftrightarrow 
    W^T \sum_{n=1}^N \phi_n \phi_n^T = \sum_{n=1}^N t_n\phi_n^T \\
    \Leftrightarrow W^T \Phi^T \Phi = T^T \Phi \\
\end{align*}

よって, 

\begin{align*}
    W_{ML}^T = T^T\Phi (\Phi^T \Phi)^{-1} \\
    W_{ML} = (\Phi^T \Phi)^{-1}\Phi^T T
\end{align*}
となり, $T$はn番目の行が$t_n^T$となるようにした行列であるから, $W_{ML}$のそれぞれの列が, 等方性のノイズ分布に対する解の
(3.15)の形の式で与えられることが分かる. \\
また$\Sigma$の最尤解は, 対数尤度関数を$\Sigma$で微分して$\textbf{0}$と置き, $\Sigma$について解くことで求まる.　\\
これは演習2.34(以前解いたもの)と全く同手順であるため省略する.

\newpage

問題3.7 \\

$\boldsymbol{m}_N$と$\boldsymbol{S}_N$がそれぞれ(3.50)と(3.51)で定義される線形基底関数モデルを考える． 
平方完成を用いて，このモデルパラメータ$\boldsymbol{w}$の事後分布が(3.49)で与えられることを確かめよ．\\

方針3.7 \\

解答3.7 \\

ベイズの公式から

\begin{align*}
    p(w|t) \propto p(t|w)p(w)
\end{align*}

(3.10),(3.48)より,

\begin{align*}
    \propto \left( \prod_{n=1}^N exp\left[ -\frac{1}{2} \left\{ t_n - w^T \phi(x_n) \right\}^2 \beta \right] \right) exp\left[ -\frac{1}{2} (w - m_0)^TS_0^{-1}(w - m_0) \right] \\
    = exp\left[  -\frac{1}{2} \left\{ \beta \sum_{n=1}^N \left( t_n - w^T\phi(x_n) \right)^2 + (w - m_0)^TS_0^{-1}(w - m_0) \right\} \right]
\end{align*}

以下では exp の中の $-\frac{1}{2}$ の中身を見ていく.

\begin{align*}
    = \beta \left( \begin{array}{c}
        t_1 - w^T\phi(x_1) \\
        \vdots\\
        t_N - w^T\phi(x_N)
        \end{array} \right)^T
        \left( \begin{array}{c}
        t_1 - w^T\phi(x_1) \\
        \vdots\\
        t_N - w^T\phi(x_N)
        \end{array} \right)
        + (w - m_0)^TS_0^{-1}(w - m_0)
\end{align*}


$w^T\phi(x_1) = \phi^T(x_1)w$なので

\[
    = \beta \left( \begin{array}{c}
        t_1 - \phi^T(x_1)w \\
        \vdots\\
        t_N - \phi^T(x_N)w
        \end{array} \right)^T
        \left( \begin{array}{c}
        t_1 - \phi^T(x_1)w \\
        \vdots\\
        t_N - \phi^T(x_N)w
        \end{array} \right)
        + (w - m_0)^TS_0^{-1}(w - m_0)
    \]

ここで,
\[
    \Phi = \left( \begin{array}{c}
        \phi^T(x_1) \\
        \vdots\\
        \phi^T(x_N)
        \end{array} \right)
    \]

であるので, 定数項を C とおくとして
\begin{align*}
    = \beta (t - \Phi w)^T(t - \Phi w) + (w - m_0)^TS_0^{-1}(w - m_0)\\
    = \beta ( w^T\Phi^T\Phi w - w^T\Phi^Tt - t^T\Phi w ) + w^TS_0^{-1}w - w^TS_0^{-1}m_0 - m_0^TS_0^{-1}w + C
\end{align*}

$S_0$ は共分散なので対称行列となる. よってその逆行列も対称行列なので $(S_0^{-1})^T = S_0^{-1}$.

\[
    = w^T(S_0^{-1} + \beta \Phi^T\Phi)w - w^T(S_0^{-1}m_0 + \beta \Phi^T t) - (S_0^{-1}m_0 + \beta \Phi^T t)^Tw + C
\]

ここで, $m_N, S_N$ はそれぞれ以下のように与えられている.

\begin{align*}
    m_N = S_N(S_0^{-1} m_0 + \beta \Phi^Tt) = S_NR\\
    S_N^{-1} = S_0^{-1} + \beta \Phi^T \Phi
\end{align*}

これらを用いて平方完成すると

\begin{align*}
    = w^TS_N^{-1}w - w^TS_N^{-1}m_N - S_N^{-1}m_Nw + C \\
    = (w-m_N)^TS^{-1}(w-m_N) + C'
\end{align*}

なおパラメータ$w$に依存しない部分を新たに定数$C'$と置いた.

以上より, Cを定数として
\[
    p(w|t) \propto C \exp {(w-m_N)^TS^{-1}(w-m_N)} 
    \]

と表せるので, モデルパラメータ$w$の事後分布が(3.49)で与えられることが分かる.

問題3.10 \\

(2.115)の結果を用いて(3.57)の積分を評価し，ベイズ線形回帰モデルの予測分布が(3.58)で与えられることを確かめよ．
ただし，入力に依存する分散は(3.59)で与えられる．

方針3.10 \\


解答3.10 \\
(3.57)の条件付き分布と事後分布は, それぞれ以下の式で表される.

\begin{align*}
p \left (t ~ | ~ \mathbf w,\beta \right ) = \mathcal { N } \left (t ~ | ~ \mathbf w^\textrm T \boldsymbol \phi (\mathbf x),\beta^{-1} \right ) 
\tag{3.3, 3.8}
\end{align*}

\begin{align*}
p \left (\mathbf w ~ | ~ \mathbf t,\alpha,\beta \right ) = \mathcal { N } \left (\mathbf w ~ | ~ \mathbf m _ N,\mathbf S_N \right )
\tag{3.49}
\end{align*}

ここで, (2.115)の式は, 
\begin{align*}
p \left (\mathbf x \right ) = \mathcal { N } \left (\mathbf { x } ~ | ~ \boldsymbol \mu ,\boldsymbol \Lambda^{-1} \right ) 
\tag{2.113}
\end{align*}
と
\begin{align*}
p \left (\mathbf y ~ | ~ \mathbf x \right ) = \mathcal { N } \left (\mathbf y ~ | ~ \mathbf A \mathbf x + \mathbf b,\mathbf L^{-1} \right ) 
\tag{2.114}
\end{align*}

が与えられた際の周辺分布だったことに注意して, (2.113)から(2.115)について, 

\begin{align*}
\mathbf y \rightarrow \textit t, \quad \mathbf x \rightarrow \mathbf w, \quad \boldsymbol \mu \rightarrow \mathbf m_N, \quad \boldsymbol \Lambda^{-1} \rightarrow \mathbf S_N,\quad  \mathbf A \rightarrow \boldsymbol \phi (\mathbf x)^\textrm T,\quad \mathbf L^{-1}→\beta^{-1}
\end{align*}

と置き換えると, (3.57)を評価することができる.

したがって, (2.115)にそれぞれを代入すると,

\begin{align*}
p \left (t ~ | ~ \mathbf x,\mathbf t,\alpha,\beta \right ) = \mathcal { N } \left (t ~ | ~ \mathbf m^\textrm T_N \boldsymbol \phi (\mathbf x),\sigma ^2_N (\mathbf x) \right ) 
\tag{3.58}
\end{align*}

と求まる. 
ここで, 入力に依存する分散は, 

\begin{align*}
\sigma ^ 2 _ N (\mathbf x) = \frac{1}{\beta}+\boldsymbol \phi (\mathbf x)^\textrm T \mathbf S_N \boldsymbol \phi (\mathbf x)
\tag{3.59}
\end{align*}

である.

問題3.15 \\
線形基底関数からなる回帰モデルの超パラメータ$\alpha$,$\beta$をエビデンス枠組みを用いて決定する場合を考える.(3.82)で定義される関数$E(m_N)$が関係式
$2E(m_N) = N$を満たすことを示せ\\

解答3.15 \\
エビデンス関数を最大にする$\alpha$と$\beta$は(3.92)式と(3.95)式より

\begin{align*}
    \left\{
        \begin{array}{l}
            \alpha = \cfrac{\gamma}{m_N^T m_N} \\
            \beta = (N-\gamma)\{ \sum_{n=1}^N \{ t_N - m_N^T \phi(x_N) \}^2 \}^{-1}
        \end{array}
        \right.
\end{align*}

これらを(3.82)式に代入すると

\begin{eqnarray*}
    E(m_N) &=& \cfrac{\beta}{2}|| t - \phi m_N ||^2 + \cfrac{\alpha}{2} m_N^T m_N \\
    &=& \cfrac{N-\gamma}{2} + \cfrac{\gamma}{2} \\
    &=& \cfrac{N}{2}
\end{eqnarray*}

なお

\begin{align*}
    || t - \phi m_N ||^2 = \sum_{n=1} (t_n - m_N^T \phi(x_n))^2
\end{align*}

である。

\end{document}
